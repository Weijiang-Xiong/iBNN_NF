{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from models import LeNet, StoLeNet\n",
    "from utils import compute_accuracy, compute_ece_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_deterministic = True # train a deterministic model as starting point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# setup device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data folder\n",
    "data_dir = \"./data\"\n",
    "fig_dir = \"./figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, transform=transform, download=False)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, transform=transform, download=False)\n",
    "trainset, testset = Subset(trainset, range(300)), Subset(testset, range(300))\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "                'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================== #\n",
    "# ========= train a deterministic model =============== #\n",
    "# ===================================================== #\n",
    "if train_deterministic:\n",
    "    num_epochs = 10\n",
    "    base_model = LeNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(base_model.parameters(), lr=0.002, momentum=0.9)\n",
    "\n",
    "    loss_list, acc_list, ece_list = [[] for _ in range(3)]\n",
    "    for epoch in range(num_epochs):\n",
    "        base_model.train()\n",
    "        batch_loss = []\n",
    "        for img, label in trainloader:\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            pred = base_model(img)\n",
    "            loss = criterion(pred, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_loss.append(loss.item())\n",
    "            \n",
    "        avg_loss = sum(batch_loss)/len(batch_loss)\n",
    "        base_acc = compute_accuracy(base_model, testloader, device=device)\n",
    "        base_ece = compute_ece_loss(base_model, testloader, device=device)\n",
    "        print(\"Base Model Epoch {} Avg Loss {:.4f} Acc {:.4f} ECE {:.4f}\".format(epoch, avg_loss, base_acc, base_ece))\n",
    "        loss_list.append(avg_loss)\n",
    "        acc_list.append(base_acc)\n",
    "        ece_list.append(base_ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_deterministic:\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(loss_list)\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(acc_list)\n",
    "    plt.title(\"Test Accuracy\")\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(ece_list)\n",
    "    plt.title(\"ECE on Test Set\")\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fig_dir + \"/\" + \"LeNet_FMNIST.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================== #\n",
    "# =  migrate from base model, finetune and train flow = #\n",
    "# ===================================================== #\n",
    "\n",
    "# parameters for base distribution \n",
    "NormalParams = lambda scale: {\"loc\":1.0, \"scale\":scale}\n",
    "# flow configurations, List of tuple (type, depth, params)\n",
    "AffineLayer = [(\"affine\", 1, {\"learnable\":True})]\n",
    "GlowStep =  lambda depth, width:[\n",
    "            (\"affine\", 1, {\"learnable\":True}), # the first stack of flows (type, depth, params)\n",
    "            (\"planar2d\", 1, {\"init_sigma\":0.01}),# the second stack of flows (type, depth, params)\n",
    "            (\"flowstep\", depth, {\"width\":width,\"keepdim\":True}),\n",
    "            (\"planar2d\", 1, {\"init_sigma\":0.01})] \n",
    "Planar1d = lambda depth: [(\"affine\", 1), \n",
    "            (\"planar\", depth),\n",
    "            (\"element\", 1, {\"act\":\"tanh\"})]\n",
    "# stochastic part for a layer, base distribution name, distribution parameters, flow config \n",
    "NormalAffine = (\"normal\", NormalParams(0.5), AffineLayer)\n",
    "NormalGlowStep = (\"normal\", NormalParams(0.5), GlowStep(3, 0.3))\n",
    "NormalPlanar1d = (\"normal\", NormalParams(0.5), Planar1d(2))\n",
    "# flow config for all layers in the model  \n",
    "sto_model_cfg = [NormalAffine, NormalGlowStep, NormalAffine, NormalPlanar1d, NormalAffine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sto_model(sto_model:nn.Module, trainloader=None, testloader=None, base_model=None, num_epochs=30, device=None):\n",
    "    \n",
    "    if isinstance(base_model, sto_model.DET_MODEL_CLASS):\n",
    "        sto_model.migrate_from_det_model(base_model)\n",
    "\n",
    "    det_params, sto_params = sto_model.det_and_sto_params()\n",
    "    optimizer = optim.Adam([\n",
    "                    {'params': det_params, 'lr': 2e-4},\n",
    "                    {'params': sto_params, 'lr': 2e-3}\n",
    "                ])\n",
    "\n",
    "    loss_list, ll_list, kl_list, acc_list, ece_list = [[] for _ in range(5)]\n",
    "    for epoch in range(num_epochs):\n",
    "        sto_model.train()\n",
    "        batch_loss, batch_ll, batch_kl = [[] for _ in range(3)]\n",
    "        for img, label in trainloader:\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            pred = sto_model(img)\n",
    "            log_likelihood, kl = sto_model.calc_loss(pred, label)\n",
    "            loss = -log_likelihood + kl / len(trainloader.dataset)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_loss.append(loss.item())\n",
    "            batch_ll.append(log_likelihood.item()) \n",
    "            batch_kl.append(kl.item()/ len(trainloader.dataset))\n",
    "        avg = lambda l: sum(l)/len(l)\n",
    "        avg_loss, avg_ll, avg_kl = avg(batch_loss), avg(batch_ll), avg(batch_kl)\n",
    "        sto_acc = compute_accuracy(sto_model, testloader)\n",
    "        sto_ece = compute_ece_loss(sto_model, testloader)\n",
    "        print(\"Sto Model Epoch {} Avg Loss {:.4f} Likelihood {:.4f} KL {:.4f} Acc {:.4f} ECE {:.4f}\".format(\n",
    "                            epoch, avg_loss, avg_ll, avg_kl,sto_acc, sto_ece))\n",
    "        loss_list.append(avg_loss)\n",
    "        ll_list.append(avg_ll)\n",
    "        kl_list.append(avg_kl)\n",
    "        acc_list.append(sto_acc)\n",
    "        ece_list.append(sto_ece)\n",
    "\n",
    "    return loss_list, ll_list, kl_list, acc_list, ece_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sto_model = StoLeNet(sto_cfg=sto_model_cfg, colored=False).to(device)\n",
    "result1 = train_sto_model(sto_model, trainloader, testloader, base_model, num_epochs=30, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, anno=\"\"):\n",
    "    loss_list, ll_list, kl_list, acc_list, ece_list = results \n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.plot(loss_list)\n",
    "    plt.title(\"Negative ELBO\")\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.plot(ll_list)\n",
    "    plt.title(\"Log Likelihood\")\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.plot(kl_list)\n",
    "    plt.title(\"KL Divergence\")\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.plot(acc_list)\n",
    "    plt.title(\"Test Accuracy\")\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.plot(ece_list)\n",
    "    plt.title(\"ECE on testset\")\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fig_dir + \"/\" + \"{}.jpg\".format(anno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result1, anno=\"StoLeNet_flow_FMNIST\")"
   ]
  },
  {
   "source": [
    "better results compared to last week (without the \"step of flow\" in Glow paper)\n",
    "\n",
    "last time the ECE goes higher as training goes on, this time it's lower than the deterministic LeNet\n",
    "\n",
    "should probably take the check point arount epoch 10~15, the model seems to overfit after about 20 epochs \n",
    "\n",
    "the accuracy increases (84% => 89%): model capacity has been increased by the stochastic part (some has a flow, others don't)\n",
    "\n",
    "ece is slightly lower (0.01 => 0.004): model is better calibrated, so the flow helps \n",
    "\n",
    "if we remove all flows (only keep the base gaussian distribution together with an affine transformation)\n",
    "\n",
    "the results is almost as good as the complicated model with flow. \n",
    "\n",
    "probably the best balanced results are (Acc 0.8903 ECE 0.0051), compared to the one with flow (0.8921 ECE 0.0042)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sto_model_cfg = [NormalAffine, NormalAffine, NormalAffine, NormalAffine, NormalAffine]\n",
    "sto_model = StoLeNet(sto_cfg=sto_model_cfg, colored=False).to(device)\n",
    "result2 = train_sto_model(sto_model, trainloader, testloader, base_model, num_epochs=30, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result2, anno=\"StoLeNet_no_flow_FMNIST\")"
   ]
  },
  {
   "source": [
    "## Redo on CIFAR 10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms adopted from https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform_test)\n",
    "trainset, testset = Subset(trainset, range(300)), Subset(testset, range(300))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_deterministic:\n",
    "    num_epochs = 20\n",
    "    base_model = LeNet(colored=True).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(base_model.parameters(), lr=0.002, momentum=0.9)\n",
    "\n",
    "    loss_list, acc_list, ece_list = [[] for _ in range(3)]\n",
    "    for epoch in range(num_epochs):\n",
    "        base_model.train()\n",
    "        batch_loss = []\n",
    "        for img, label in trainloader:\n",
    "            img, label = img.to(device), label.to(device)\n",
    "            pred = base_model(img)\n",
    "            loss = criterion(pred, label)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_loss.append(loss.item())\n",
    "            \n",
    "        avg_loss = sum(batch_loss)/len(batch_loss)\n",
    "        base_acc = compute_accuracy(base_model, testloader, device=device)\n",
    "        base_ece = compute_ece_loss(base_model, testloader, device=device)\n",
    "        print(\"Base Model Epoch {} Avg Loss {:.4f} Acc {:.4f} ECE {:.4f}\".format(epoch, avg_loss, base_acc, base_ece))\n",
    "        loss_list.append(avg_loss)\n",
    "        acc_list.append(base_acc)\n",
    "        ece_list.append(base_ece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_deterministic:\n",
    "    fig = plt.figure(figsize=(18, 5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.plot(loss_list)\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.plot(acc_list)\n",
    "    plt.title(\"Test Accuracy\")\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.plot(ece_list)\n",
    "    plt.title(\"ECE on Test Set\")\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(fig_dir + \"/\" + \"LeNet_CIFAR10.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sto_model_cfg = [NormalAffine, NormalGlowStep, NormalAffine, NormalPlanar1d, NormalAffine]\n",
    "sto_model = StoLeNet(sto_cfg=sto_model_cfg, colored=True).to(device)\n",
    "result3 = train_sto_model(sto_model, trainloader, testloader, base_model, num_epochs=50, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result3, anno=\"StoLeNet_flow_CIFAR10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sto_model_cfg = [NormalAffine, NormalAffine, NormalAffine, NormalAffine, NormalAffine]\n",
    "sto_model = StoLeNet(sto_cfg=sto_model_cfg, colored=True).to(device)\n",
    "result4 = train_sto_model(sto_model, trainloader, testloader, base_model, num_epochs=50, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result4, anno=\"StoLeNet_no_flow_CIFAR10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_results(result_list, anno_list, fig_dir=None, save_name=None):\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    for result in result_list:\n",
    "        loss_list, ll_list, kl_list, acc_list, ece_list = result \n",
    "        plt.subplot(2,3,1)\n",
    "        plt.plot(loss_list)\n",
    "        plt.title(\"Negative ELBO\")\n",
    "        plt.legend(anno_list)\n",
    "        plt.subplot(2,3,2)\n",
    "        plt.plot(ll_list)\n",
    "        plt.title(\"Log Likelihood\")\n",
    "        plt.legend(anno_list)\n",
    "        plt.subplot(2,3,3)\n",
    "        plt.plot(kl_list)\n",
    "        plt.title(\"KL Divergence\")\n",
    "        plt.legend(anno_list)\n",
    "        plt.subplot(2,3,4)\n",
    "        plt.plot(acc_list)\n",
    "        plt.title(\"Test Accuracy\")\n",
    "        plt.legend(anno_list)\n",
    "        plt.subplot(2,3,5)\n",
    "        plt.plot(ece_list)\n",
    "        plt.title(\"ECE on testset\")\n",
    "        plt.legend(anno_list)\n",
    "\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n",
    "    if os.path.exists(fig_dir) and save_name!=None:\n",
    "        fig.savefig(fig_dir + \"/\" + \"{}.jpg\".format(save_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = [result1, result2, result3, result4]\n",
    "anno_list = [\"FMNIST Flow\", \"FMNIST no Flow\", \"CIFAR Flow\", \"CIFAR no Flow\"]\n",
    "plot_multiple_results(result_list, anno_list, fig_dir, \"all_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6c23d29741de7e8352c8d926ff688f9c5fc67d6415374e195fed214ccf6d0166"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}